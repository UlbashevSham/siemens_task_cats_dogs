{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d0b1e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9457f33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2c8229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = pd.read_pickle(\"data/x_train.pkl\"), pd.read_pickle(\"data/y_train.pkl\")\n",
    "X_val, y_val = pd.read_pickle(\"data/x_val.pkl\"), pd.read_pickle(\"data/y_val.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aae510",
   "metadata": {},
   "source": [
    "## Соберем датасеты и загрузим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47caf6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from task_models import CatDogsData, BB_model\n",
    "train_ds = CatDogsData(X_train['new_path'],X_train['new_bb'] ,y_train, transforms=True)\n",
    "valid_ds = CatDogsData(X_val['new_path'],X_val['new_bb'],y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17bbb74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0327c195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = BB_model().cuda()\n",
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.006)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec49fc11",
   "metadata": {},
   "source": [
    "## Обучим модель. Коэффициент С служит для приведения ошибки bb и классификации к схожим уровням"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0db9281c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1.097 val_loss 1.139 val_acc 0.642\n",
      "train_loss 0.891 val_loss 6.409 val_acc 0.611\n",
      "train_loss 0.897 val_loss 0.899 val_acc 0.626\n",
      "train_loss 0.863 val_loss 0.822 val_acc 0.659\n",
      "train_loss 0.822 val_loss 0.887 val_acc 0.614\n",
      "train_loss 0.836 val_loss 0.803 val_acc 0.654\n",
      "train_loss 0.793 val_loss 0.814 val_acc 0.659\n",
      "train_loss 0.787 val_loss 0.799 val_acc 0.661\n",
      "train_loss 0.784 val_loss 0.807 val_acc 0.660\n",
      "train_loss 0.777 val_loss 0.786 val_acc 0.661\n",
      "train_loss 0.773 val_loss 0.784 val_acc 0.661\n",
      "train_loss 0.774 val_loss 0.788 val_acc 0.679\n",
      "train_loss 0.773 val_loss 0.789 val_acc 0.667\n",
      "train_loss 0.763 val_loss 0.807 val_acc 0.653\n",
      "train_loss 0.756 val_loss 0.768 val_acc 0.720\n",
      "train_loss 0.748 val_loss 0.824 val_acc 0.649\n",
      "train_loss 0.750 val_loss 0.748 val_acc 0.702\n",
      "train_loss 0.731 val_loss 0.773 val_acc 0.703\n",
      "train_loss 0.737 val_loss 0.751 val_acc 0.694\n",
      "train_loss 0.724 val_loss 0.761 val_acc 0.705\n",
      "train_loss 0.721 val_loss 0.735 val_acc 0.724\n",
      "train_loss 0.715 val_loss 0.708 val_acc 0.728\n",
      "train_loss 0.691 val_loss 0.751 val_acc 0.718\n",
      "train_loss 0.688 val_loss 0.757 val_acc 0.706\n",
      "train_loss 0.661 val_loss 0.779 val_acc 0.701\n",
      "train_loss 0.659 val_loss 0.715 val_acc 0.759\n",
      "train_loss 0.638 val_loss 0.674 val_acc 0.747\n",
      "train_loss 0.617 val_loss 0.729 val_acc 0.725\n",
      "train_loss 0.628 val_loss 0.688 val_acc 0.741\n",
      "train_loss 0.614 val_loss 0.702 val_acc 0.749\n",
      "train_loss 0.590 val_loss 0.675 val_acc 0.743\n",
      "train_loss 0.572 val_loss 0.664 val_acc 0.766\n",
      "train_loss 0.549 val_loss 0.561 val_acc 0.814\n",
      "train_loss 0.533 val_loss 0.544 val_acc 0.828\n",
      "train_loss 0.520 val_loss 0.566 val_acc 0.783\n",
      "train_loss 0.493 val_loss 0.626 val_acc 0.795\n",
      "train_loss 0.478 val_loss 0.492 val_acc 0.836\n",
      "train_loss 0.465 val_loss 0.472 val_acc 0.839\n",
      "train_loss 0.443 val_loss 0.464 val_acc 0.839\n",
      "train_loss 0.427 val_loss 0.531 val_acc 0.814\n",
      "train_loss 0.400 val_loss 0.445 val_acc 0.854\n",
      "train_loss 0.393 val_loss 0.418 val_acc 0.877\n",
      "train_loss 0.392 val_loss 0.454 val_acc 0.862\n",
      "train_loss 0.353 val_loss 0.421 val_acc 0.848\n",
      "train_loss 0.347 val_loss 0.372 val_acc 0.911\n",
      "train_loss 0.356 val_loss 0.462 val_acc 0.841\n",
      "train_loss 0.318 val_loss 0.346 val_acc 0.909\n",
      "train_loss 0.304 val_loss 0.405 val_acc 0.879\n",
      "train_loss 0.307 val_loss 0.328 val_acc 0.917\n",
      "train_loss 0.290 val_loss 0.403 val_acc 0.894\n",
      "CPU times: user 1h 14min 55s, sys: 43min 7s, total: 1h 58min 2s\n",
      "Wall time: 1h 55min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#for i in range(epochs):\n",
    "for i in range(epochs):    \n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    C=1000\n",
    "    \n",
    "    for x, y_class, y_bb in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        batch = y_class.shape[0]\n",
    "        x = x.cuda().float()\n",
    "        y_class = y_class.cuda()\n",
    "        y_bb = y_bb.cuda().float()\n",
    "#         print(y_bb.shape)\n",
    "#         print(y_class.shape)\n",
    "        out_class, out_bb = model(x)\n",
    "#         print(out_bb.shape)\n",
    "#         print(out_class.shape)\n",
    "        loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
    "        loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n",
    "        loss_bb = loss_bb.sum()\n",
    "        loss = loss_class + loss_bb/C\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total += batch\n",
    "        sum_loss += loss.item()\n",
    "    train_loss = sum_loss/total\n",
    "    \n",
    "    # Eval\n",
    "    model.eval()\n",
    "    val_total = 0\n",
    "    val_sum_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for x, y_class, y_bb in valid_dl:\n",
    "        batch = y_class.shape[0]\n",
    "        x = x.cuda().float()\n",
    "        y_class = y_class.cuda()\n",
    "        y_bb = y_bb.cuda().float()\n",
    "        out_class, out_bb = model(x)\n",
    "        loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
    "\n",
    "        loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n",
    "        loss_bb = loss_bb.sum()\n",
    "        loss = loss_class + loss_bb/C\n",
    "        _, pred = torch.max(out_class, 1)\n",
    "        correct += pred.eq(y_class).sum().item()\n",
    "        val_sum_loss += loss.item()\n",
    "        val_total += batch\n",
    "    val_loss = val_sum_loss/val_total\n",
    "    val_acc = correct/val_total\n",
    "    \n",
    "    print(\"train_loss %.3f val_loss %.3f val_acc %.3f\" % (train_loss, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a9fa06",
   "metadata": {},
   "source": [
    "## Сохраним модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "715a7f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"data/resnet34\"\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
